{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kierstenhenderson/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "#import data_helpers\n",
    "#from text_cnn import TextCNN\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib.learn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on our EDA\n",
    "max_length = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/dataset1_shortjokes_uci_cnn.csv')\n",
    "#for lowercase \n",
    "df.text = df.text.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[me narrating a documentary about narrators] \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>telling my daughter garlic is good for you. go...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i've been going through a really rough period ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if i could have dinner with anyone, dead or al...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>two guys walk into a bar. the third guy ducks.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  funny  not_funny\n",
       "0  [me narrating a documentary about narrators] \"...      1          0\n",
       "1  telling my daughter garlic is good for you. go...      1          0\n",
       "2  i've been going through a really rough period ...      1          0\n",
       "3  if i could have dinner with anyone, dead or al...      1          0\n",
       "4     two guys walk into a bar. the third guy ducks.      1          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6)\n",
    "shuffle = np.random.permutation(np.arange(df.shape[0]))\n",
    "\n",
    "X = df['text']\n",
    "Y_1 = df['funny']\n",
    "Y_2 = df['not_funny']      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y_1, Y_2 = X[shuffle], Y_1[shuffle],Y_2[shuffle]\n",
    "#Y = Y[shuffle]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame({\"funny\": Y_1.values,\"not_funny\": Y_2.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   funny  not_funny\n",
       "0      1          0\n",
       "1      1          0\n",
       "2      1          0\n",
       "3      1          0\n",
       "4      0          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (463314,)\n",
      "label shape: (463314, 2)\n",
      "test_data (46331,)\n",
      "dev_data (92663,)\n",
      "train_data (324320,)\n"
     ]
    }
   ],
   "source": [
    "print('data shape: ', X.shape)\n",
    "print('label shape:', Y.shape)\n",
    "\n",
    "\n",
    "test_data, test_label = X[round(X.shape[0]*.9):], Y[round(Y.shape[0]*.9):]\n",
    "dev_data, dev_label = X[round(X.shape[0]*.7):round(X.shape[0]*.9)], Y[round(Y.shape[0]*.7):round(Y.shape[0]*.9)]\n",
    "train_data, train_label = X[:round(X.shape[0]*.7)], Y[:round(Y.shape[0]*.7)]\n",
    "\n",
    "\n",
    "print('test_data', test_data.shape)\n",
    "print('dev_data', dev_data.shape)\n",
    "print('train_data', train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-9558eb373733>:3: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From /home/kierstenhenderson/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "WARNING:tensorflow:From /home/kierstenhenderson/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n",
      "unique vocab count: 98302\n"
     ]
    }
   ],
   "source": [
    "max_doc_len = 34\n",
    "# Setup vocabulary processor\n",
    "processor = preprocessing.VocabularyProcessor(max_doc_len)\n",
    "\n",
    "#vocab_processor = tflearn.data_utils.VocabularyProcessor(max_length, min_frequency=0)\n",
    "\n",
    "\n",
    "processor.fit(train_data)\n",
    "train = processor.transform(train_data)\n",
    "dev = processor.transform(dev_data)\n",
    "test = processor.transform(test_data)\n",
    "\n",
    "V = len(processor.vocabulary_)\n",
    "print(\"unique vocab count:\", V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(324320, 34)\n",
      "(324320, 2)\n"
     ]
    }
   ],
   "source": [
    "# Inputs need to be np.arrays instead of generators\n",
    "x_train = np.array(list(train))\n",
    "print(x_train.shape)\n",
    "\n",
    "x_dev = np.array(list(dev))\n",
    "\n",
    "x_test = np.array(list(test))\n",
    "\n",
    "y_train = np.array(train_label).astype(int)\n",
    "y_dev = np.array(dev_label).astype(int)\n",
    "y_test = np.array(test_label).astype(int)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corresponding ids\n",
      " [1 2 3 4 1 5 6 7 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "corresponding ids\n",
      " [1 0]\n",
      "corresponding ids\n",
      " [ 9 10 11 12 13 14 15 16 17  4 17 18 19  4 17 20 17  4 19 21 19  4 19  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "corresponding ids\n",
      " [22 23 24 25  4 26 27  1 28  4 29 30 31 32 33 29 34 23 35 36 24 37  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "corresponding ids\n",
      " [  45   31   42 1890 2644  396   42  519 6852 6853    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the worst journey in the world by helen back'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('corresponding ids\\n',x_train[0])\n",
    "print('corresponding ids\\n',y_train[0])\n",
    "\n",
    "print('corresponding ids\\n',x_train[1])\n",
    "print('corresponding ids\\n',x_train[2])\n",
    "print('corresponding ids\\n',x_train[2000])\n",
    "train_data.iloc[0]\n",
    "train_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(object):\n",
    "    \"\"\"\n",
    "    A CNN for text classification.\n",
    "    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "      self, sequence_length, num_classes, vocab_size,\n",
    "      embedding_size, filter_sizes, num_filters, l2_reg_lambda=0.0):\n",
    "\n",
    "        # Placeholders for input, output and dropout\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, num_classes], name=\"input_y\")\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "        # Keeping track of l2 regularization loss (optional)\n",
    "        l2_loss = tf.constant(0.0)\n",
    "\n",
    "        # Embedding layer\n",
    "        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "            self.W = tf.Variable(\n",
    "                tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0),\n",
    "                name=\"W\")\n",
    "            self.embedded_chars = tf.nn.embedding_lookup(self.W, self.input_x)\n",
    "            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n",
    "\n",
    "        # Create a convolution + maxpool layer for each filter size\n",
    "        pooled_outputs = []\n",
    "        for i, filter_size in enumerate(filter_sizes):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "                # Convolution Layer\n",
    "                filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "                Wname = \"w_%d\"%filter_size\n",
    "                #W = tf.get_variable(Wname, shape = filter_shape, initializer = tf.contrib.layers.xavier_initializer())\n",
    "                W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "                \n",
    "                b = tf.Variable(tf.constant(0.0, shape=[num_filters]), name=\"b\")\n",
    "                conv = tf.nn.conv2d(\n",
    "                    self.embedded_chars_expanded,\n",
    "                    W,\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding=\"VALID\",\n",
    "                    name=\"conv\")\n",
    "                \n",
    "                # Apply nonlinearity\n",
    "                h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "                \n",
    "                # Maxpooling over the outputs\n",
    "                pooled = tf.nn.max_pool(\n",
    "                    h,\n",
    "                    ksize=[1, sequence_length - filter_size + 1, 1, 1],\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding='VALID',\n",
    "                    name=\"pool\")\n",
    "                pooled_outputs.append(pooled)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        num_filters_total = num_filters * len(filter_sizes)\n",
    "        \n",
    "        #the line below differs from the tutorial, but is necessary based on changes to Tensorflow\n",
    "        self.h_pool = tf.concat(pooled_outputs, 3)\n",
    "\n",
    "        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
    "\n",
    "        # Add dropout\n",
    "        with tf.name_scope(\"dropout\"):\n",
    "            self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keep_prob)\n",
    "\n",
    "        # Final (unnormalized) scores and predictions\n",
    "        with tf.name_scope(\"output\"):\n",
    "            W = tf.get_variable(\n",
    "                \"W\",\n",
    "                shape=[num_filters_total, num_classes],\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.Variable(tf.constant(0.0, shape=[num_classes]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            self.scores = tf.nn.xw_plus_b(self.h_drop, W, b, name=\"scores\")\n",
    "            print(\"scores shape:\", self.scores.shape)\n",
    "            self.predictions = tf.argmax(self.scores, 1, name=\"predictions\")\n",
    "\n",
    "        # Calculate mean cross-entropy loss\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss\n",
    "\n",
    "        # Accuracy\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            \n",
    "            #correct_predictions = tf.equal(tf.cast(self.predictions,tf.float32), self.input_y)\n",
    "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n",
    "\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")\n",
    "        \n",
    "        with tf.name_scope('train'):\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(ids, labels, batch_size=100):\n",
    "            \n",
    "    n_batches = len(ids)//batch_size\n",
    "    ids, labels = ids[:n_batches*batch_size], labels[:n_batches*batch_size]\n",
    "    shuffle = np.random.permutation(np.arange(n_batches*batch_size))\n",
    "    ids, labels = ids[shuffle], labels[shuffle]\n",
    "\n",
    "    \n",
    "    for ii in range(0, len(ids), batch_size):\n",
    "        yield ids[ii:ii+batch_size], labels[ii:ii+batch_size]\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CNN without Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /home/kierstenhenderson/Final_project/runs/cnn\n",
      "\n",
      "scores shape: (?, 2)\n",
      "WARNING:tensorflow:From <ipython-input-14-5542c80aa699>:83: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "completed cnn creation\n",
      "# batches = 5067\n",
      "Train epoch 0, average loss 0.263021, average accuracy 0.954824,\n",
      "\t\tDev epoch 0, average loss 0.235399, average accuracy 0.960824,\n",
      "\t\t\t\t    Time taken for 0 epochs =  498.50074577331543\n",
      "Train epoch 1, average loss 0.259959, average accuracy 0.970551,\n",
      "\t\tDev epoch 1, average loss 0.275175, average accuracy 0.962768,\n",
      "Train epoch 2, average loss 0.262379, average accuracy 0.975411,\n",
      "\t\tDev epoch 2, average loss 0.443942, average accuracy 0.963815,\n",
      "Train epoch 3, average loss 0.26728, average accuracy 0.977591,\n",
      "\t\tDev epoch 3, average loss 0.885046, average accuracy 0.964582,\n",
      "Train epoch 4, average loss 0.279552, average accuracy 0.977958,\n",
      "\t\tDev epoch 4, average loss 1.28894, average accuracy 0.959874,\n",
      "Train epoch 5, average loss 0.256771, average accuracy 0.979432,\n",
      "\t\tDev epoch 5, average loss 1.44074, average accuracy 0.960511,\n",
      "Train epoch 6, average loss 0.266916, average accuracy 0.978374,\n",
      "\t\tDev epoch 6, average loss 2.19662, average accuracy 0.955317,\n",
      "Train epoch 7, average loss 0.290303, average accuracy 0.980332,\n",
      "\t\tDev epoch 7, average loss 3.40524, average accuracy 0.952283,\n",
      "Train epoch 8, average loss 0.327402, average accuracy 0.978198,\n",
      "\t\tDev epoch 8, average loss 2.58165, average accuracy 0.951203,\n",
      "Train epoch 9, average loss 0.298685, average accuracy 0.97912,\n",
      "\t\tDev epoch 9, average loss 4.06975, average accuracy 0.958081,\n"
     ]
    }
   ],
   "source": [
    "#Basic training loop:\n",
    "embed_dim = 300 \n",
    "filter_sizes= [3,4,5]\n",
    "num_filters = 100\n",
    "l2_reg_lambda = 0\n",
    "learning_rate = 0.01\n",
    "keep_prob = 1.0\n",
    "evaluate_train = 1 # of epochs at which to print test accuracy\n",
    "evaluate_dev = 1 # of epochs at which to estimate and print dev accuracy\n",
    "time_print = 12 # of epochs at which to print time taken\n",
    "num_classes = 2\n",
    "num_epochs = 10\n",
    "\n",
    "num_checkpoints = 1\n",
    "batch_size = 64\n",
    "\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", \"cnn\"))\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        cnn = TextCNN(sequence_length=x_train.shape[1], num_classes=num_classes, vocab_size=V, embedding_size=embed_dim, filter_sizes= filter_sizes, \n",
    "                      num_filters=num_filters, l2_reg_lambda=l2_reg_lambda)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('completed cnn creation')\n",
    "\n",
    "        # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "        checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=num_checkpoints)\n",
    "\n",
    "        \n",
    "\n",
    "        print('# batches =', len(x_train)//batch_size)\n",
    "        start = time.time()\n",
    "        for e in range(num_epochs):\n",
    "                    \n",
    "            #sum_scores = np.zeros((batch_size*(len(x_train)//batch_size),1))\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            for i, (x, y) in enumerate(batch_generator(x_train, y_train, batch_size), 1):\n",
    "                feed = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: keep_prob}\n",
    "                _, scores, loss, accuracy = sess.run([cnn.optimizer,cnn.scores,cnn.loss, cnn.accuracy],feed_dict = feed)\n",
    "                total_loss += loss*len(x)\n",
    "                total_acc += accuracy*len(x)\n",
    "                \n",
    "                #sum_scores[i*batch_size:(i+1)*batch_size,:] = scores\n",
    "                #print(np.mean(sum_scores))\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "            if e%evaluate_train==0:\n",
    "                avg_loss = total_loss/(batch_size*(len(x_train)//batch_size))\n",
    "                avg_acc = total_acc/(batch_size*(len(x_train)//batch_size))\n",
    "                print(\"Train epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "                #print('average',np.mean(scores))\n",
    "\n",
    "            if e%evaluate_dev==0:\n",
    "                total_loss = 0\n",
    "                total_acc = 0\n",
    "                num_batches = 0\n",
    "                for ii, (x, y) in enumerate(batch_generator(x_dev, y_dev, batch_size), 1):\n",
    "                    feed_dict = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: 1.0}\n",
    "                    loss, accuracy = sess.run([cnn.loss, cnn.accuracy],feed_dict)\n",
    "                    total_loss += loss*len(x)\n",
    "                    total_acc += accuracy*len(x)\n",
    "                    num_batches += 1\n",
    "                avg_loss = total_loss/(num_batches*batch_size)\n",
    "                avg_acc = total_acc/(num_batches*batch_size)\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "                print(\"\\t\\tDev epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "            if e%time_print == 0:\n",
    "                end = time.time()\n",
    "                print(\"\\t\\t\\t\\t    Time taken for\",e,\"epochs = \", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with Dropout 0.5, 256 filters, learning rate 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /home/kierstenhenderson/Final_project/runs/cnn\n",
      "\n",
      "scores shape: (?, 2)\n",
      "WARNING:tensorflow:From <ipython-input-38-1213db3c714d>:83: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "completed cnn creation\n",
      "# batches = 5067\n",
      "Train epoch 0, average loss 1.07881, average accuracy 0.934925,\n",
      "\t\tDev epoch 0, average loss 0.870611, average accuracy 0.954615,\n",
      "\t\t\t\t    Time taken for 0 epochs =  652.840256690979\n",
      "Train epoch 1, average loss 1.0042, average accuracy 0.940852,\n",
      "\t\tDev epoch 1, average loss 0.986357, average accuracy 0.945199,\n",
      "Train epoch 2, average loss 1.0126, average accuracy 0.932924,\n",
      "\t\tDev epoch 2, average loss 1.68322, average accuracy 0.928408,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-85745088d492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_keep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mtotal_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Basic training loop:\n",
    "embed_dim = 300 \n",
    "filter_sizes= [3,4,5]\n",
    "num_filters = 256\n",
    "l2_reg_lambda = 0\n",
    "learning_rate = 0.01\n",
    "keep_prob = 0.5\n",
    "evaluate_train = 1 # of epochs at which to print test accuracy\n",
    "evaluate_dev = 1 # of epochs at which to estimate and print dev accuracy\n",
    "time_print = 12 # of epochs at which to print time taken\n",
    "num_classes = 2\n",
    "num_epochs = 10\n",
    "\n",
    "num_checkpoints = 1\n",
    "batch_size = 64\n",
    "\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", \"cnn\"))\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        cnn = TextCNN(sequence_length=x_train.shape[1], num_classes=num_classes, vocab_size=V, embedding_size=embed_dim, filter_sizes= filter_sizes, \n",
    "                      num_filters=num_filters, l2_reg_lambda=l2_reg_lambda)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('completed cnn creation')\n",
    "\n",
    "        # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "        checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=num_checkpoints)\n",
    "\n",
    "        \n",
    "\n",
    "        print('# batches =', len(x_train)//batch_size)\n",
    "        start = time.time()\n",
    "        for e in range(num_epochs):\n",
    "                    \n",
    "            #sum_scores = np.zeros((batch_size*(len(x_train)//batch_size),1))\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            for i, (x, y) in enumerate(batch_generator(x_train, y_train, batch_size), 1):\n",
    "                feed = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: keep_prob}\n",
    "                _, scores, loss, accuracy = sess.run([cnn.optimizer,cnn.scores,cnn.loss, cnn.accuracy],feed_dict = feed)\n",
    "                total_loss += loss*len(x)\n",
    "                total_acc += accuracy*len(x)\n",
    "                \n",
    "                #sum_scores[i*batch_size:(i+1)*batch_size,:] = scores\n",
    "                #print(np.mean(sum_scores))\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "            if e%evaluate_train==0:\n",
    "                avg_loss = total_loss/(batch_size*(len(x_train)//batch_size))\n",
    "                avg_acc = total_acc/(batch_size*(len(x_train)//batch_size))\n",
    "                print(\"Train epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "                #print('average',np.mean(scores))\n",
    "\n",
    "            if e%evaluate_dev==0:\n",
    "                total_loss = 0\n",
    "                total_acc = 0\n",
    "                num_batches = 0\n",
    "                for ii, (x, y) in enumerate(batch_generator(x_dev, y_dev, batch_size), 1):\n",
    "                    feed_dict = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: 1.0}\n",
    "                    loss, accuracy = sess.run([cnn.loss, cnn.accuracy],feed_dict)\n",
    "                    total_loss += loss*len(x)\n",
    "                    total_acc += accuracy*len(x)\n",
    "                    num_batches += 1\n",
    "                avg_loss = total_loss/(num_batches*batch_size)\n",
    "                avg_acc = total_acc/(num_batches*batch_size)\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "                print(\"\\t\\tDev epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "            if e%time_print == 0:\n",
    "                end = time.time()\n",
    "                print(\"\\t\\t\\t\\t    Time taken for\",e,\"epochs = \", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decrease learning rate to mitigate Overfitting (0.01 to 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /home/kierstenhenderson/Final_project/runs/cnn\n",
      "\n",
      "scores shape: (?, 2)\n",
      "WARNING:tensorflow:From <ipython-input-12-1213db3c714d>:83: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "completed cnn creation\n",
      "# batches = 5067\n",
      "Train epoch 0, average loss 0.169832, average accuracy 0.951321,\n",
      "\t\tDev epoch 0, average loss 0.0672177, average accuracy 0.97808,\n",
      "\t\t\t\t    Time taken for 0 epochs =  722.7192435264587\n",
      "Train epoch 1, average loss 0.0586678, average accuracy 0.982466,\n",
      "\t\tDev epoch 1, average loss 0.0609224, average accuracy 0.983036,\n",
      "Train epoch 2, average loss 0.0375557, average accuracy 0.989608,\n",
      "\t\tDev epoch 2, average loss 0.078718, average accuracy 0.982917,\n",
      "Train epoch 3, average loss 0.0280478, average accuracy 0.993413,\n",
      "\t\tDev epoch 3, average loss 0.109895, average accuracy 0.982852,\n",
      "Train epoch 4, average loss 0.0226164, average accuracy 0.995236,\n",
      "\t\tDev epoch 4, average loss 0.152929, average accuracy 0.982226,\n",
      "Train epoch 5, average loss 0.0200577, average accuracy 0.996253,\n",
      "\t\tDev epoch 5, average loss 0.205529, average accuracy 0.982053,\n",
      "Train epoch 6, average loss 0.019095, average accuracy 0.996901,\n",
      "\t\tDev epoch 6, average loss 0.248724, average accuracy 0.981848,\n",
      "Train epoch 7, average loss 0.0168639, average accuracy 0.997548,\n",
      "\t\tDev epoch 7, average loss 0.315974, average accuracy 0.982053,\n",
      "Train epoch 8, average loss 0.0186163, average accuracy 0.997814,\n",
      "\t\tDev epoch 8, average loss 0.367407, average accuracy 0.981794,\n",
      "Train epoch 9, average loss 0.0182505, average accuracy 0.998039,\n",
      "\t\tDev epoch 9, average loss 0.414568, average accuracy 0.982377,\n"
     ]
    }
   ],
   "source": [
    "#Actual training loop:\n",
    "embed_dim = 300 \n",
    "filter_sizes= [3,4,5]\n",
    "num_filters = 256\n",
    "l2_reg_lambda = 0\n",
    "learning_rate = 0.001\n",
    "keep_prob = 0.5\n",
    "evaluate_train = 1 # of epochs at which to print test accuracy\n",
    "evaluate_dev = 1 # of epochs at which to estimate and print dev accuracy\n",
    "time_print = 12 # of epochs at which to print time taken\n",
    "num_classes = 2\n",
    "num_epochs = 10\n",
    "\n",
    "num_checkpoints = 1\n",
    "batch_size = 64\n",
    "\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", \"cnn\"))\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        cnn = TextCNN(sequence_length=x_train.shape[1], num_classes=num_classes, vocab_size=V, embedding_size=embed_dim, filter_sizes= filter_sizes, \n",
    "                      num_filters=num_filters, l2_reg_lambda=l2_reg_lambda)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('completed cnn creation')\n",
    "\n",
    "        # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "        checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=num_checkpoints)\n",
    "\n",
    "        print('# batches =', len(x_train)//batch_size)\n",
    "        start = time.time()\n",
    "        for e in range(num_epochs):\n",
    "                    \n",
    "            #sum_scores = np.zeros((batch_size*(len(x_train)//batch_size),1))\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            for i, (x, y) in enumerate(batch_generator(x_train, y_train, batch_size), 1):\n",
    "                feed = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: keep_prob}\n",
    "                _, scores, loss, accuracy = sess.run([cnn.optimizer,cnn.scores,cnn.loss, cnn.accuracy],feed_dict = feed)\n",
    "                total_loss += loss*len(x)\n",
    "                total_acc += accuracy*len(x)\n",
    "                \n",
    "                #sum_scores[i*batch_size:(i+1)*batch_size,:] = scores\n",
    "                #print(np.mean(sum_scores))\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "            if e%evaluate_train==0:\n",
    "                avg_loss = total_loss/(batch_size*(len(x_train)//batch_size))\n",
    "                avg_acc = total_acc/(batch_size*(len(x_train)//batch_size))\n",
    "                print(\"Train epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "                #print('average',np.mean(scores))\n",
    "\n",
    "            if e%evaluate_dev==0:\n",
    "                total_loss = 0\n",
    "                total_acc = 0\n",
    "                num_batches = 0\n",
    "                for ii, (x, y) in enumerate(batch_generator(x_dev, y_dev, batch_size), 1):\n",
    "                    feed_dict = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: 1.0}\n",
    "                    loss, accuracy = sess.run([cnn.loss, cnn.accuracy],feed_dict)\n",
    "                    total_loss += loss*len(x)\n",
    "                    total_acc += accuracy*len(x)\n",
    "                    num_batches += 1\n",
    "                avg_loss = total_loss/(num_batches*batch_size)\n",
    "                avg_acc = total_acc/(num_batches*batch_size)\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "                print(\"\\t\\tDev epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "            if e%time_print == 0:\n",
    "                end = time.time()\n",
    "                print(\"\\t\\t\\t\\t    Time taken for\",e,\"epochs = \", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decrease learning rate again to mitigate Overfitting (0.001 to 0.0001)\n",
    "- ran 12/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /home/kierstenhenderson/Final_project/runs/cnn\n",
      "\n",
      "scores shape: (?, 2)\n",
      "completed cnn creation\n",
      "# batches = 5067\n",
      "Train epoch 0, average loss 0.50275, average accuracy 0.876388,\n",
      "\t\tDev epoch 0, average loss 0.129351, average accuracy 0.954172,\n",
      "\t\t\t\t    Time taken for 0 epochs =  652.1811921596527\n",
      "Train epoch 1, average loss 0.152941, average accuracy 0.943933,\n",
      "\t\tDev epoch 1, average loss 0.0981918, average accuracy 0.964312,\n",
      "Train epoch 2, average loss 0.102196, average accuracy 0.962453,\n",
      "\t\tDev epoch 2, average loss 0.0870992, average accuracy 0.967875,\n",
      "Train epoch 3, average loss 0.0753122, average accuracy 0.972333,\n",
      "\t\tDev epoch 3, average loss 0.0673719, average accuracy 0.975153,\n",
      "Train epoch 4, average loss 0.058899, average accuracy 0.978528,\n",
      "\t\tDev epoch 4, average loss 0.0626418, average accuracy 0.977075,\n",
      "Train epoch 5, average loss 0.0478803, average accuracy 0.982697,\n",
      "\t\tDev epoch 5, average loss 0.0576026, average accuracy 0.978674,\n",
      "Train epoch 6, average loss 0.0384907, average accuracy 0.986068,\n",
      "\t\tDev epoch 6, average loss 0.0557125, average accuracy 0.980034,\n",
      "Train epoch 7, average loss 0.0304576, average accuracy 0.989068,\n",
      "\t\tDev epoch 7, average loss 0.055265, average accuracy 0.980974,\n",
      "Train epoch 8, average loss 0.0252585, average accuracy 0.990937,\n",
      "\t\tDev epoch 8, average loss 0.0559349, average accuracy 0.981578,\n",
      "Train epoch 9, average loss 0.0204566, average accuracy 0.992763,\n",
      "\t\tDev epoch 9, average loss 0.0580537, average accuracy 0.981449,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1b653c5b3a6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_keep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mtotal_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Actual training loop:\n",
    "embed_dim = 300 \n",
    "filter_sizes= [3,4,5]\n",
    "num_filters = 256\n",
    "l2_reg_lambda = 0\n",
    "learning_rate = 0.0001\n",
    "keep_prob = 0.5\n",
    "evaluate_train = 1 # of epochs at which to print test accuracy\n",
    "evaluate_dev = 1 # of epochs at which to estimate and print dev accuracy\n",
    "time_print = 12 # of epochs at which to print time taken\n",
    "num_classes = 2\n",
    "num_epochs = 15\n",
    "\n",
    "num_checkpoints = 1\n",
    "batch_size = 64\n",
    "\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", \"cnn\"))\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        cnn = TextCNN(sequence_length=x_train.shape[1], num_classes=num_classes, vocab_size=V, embedding_size=embed_dim, filter_sizes= filter_sizes, \n",
    "                      num_filters=num_filters, l2_reg_lambda=l2_reg_lambda)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('completed cnn creation')\n",
    "\n",
    "        # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "        checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=num_checkpoints)\n",
    "\n",
    "        print('# batches =', len(x_train)//batch_size)\n",
    "        start = time.time()\n",
    "        for e in range(num_epochs):\n",
    "                    \n",
    "            #sum_scores = np.zeros((batch_size*(len(x_train)//batch_size),1))\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            for i, (x, y) in enumerate(batch_generator(x_train, y_train, batch_size), 1):\n",
    "                feed = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: keep_prob}\n",
    "                _, scores, loss, accuracy = sess.run([cnn.optimizer,cnn.scores,cnn.loss, cnn.accuracy],feed_dict = feed)\n",
    "                total_loss += loss*len(x)\n",
    "                total_acc += accuracy*len(x)\n",
    "                \n",
    "                #sum_scores[i*batch_size:(i+1)*batch_size,:] = scores\n",
    "                #print(np.mean(sum_scores))\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "            if e%evaluate_train==0:\n",
    "                avg_loss = total_loss/(batch_size*(len(x_train)//batch_size))\n",
    "                avg_acc = total_acc/(batch_size*(len(x_train)//batch_size))\n",
    "                print(\"Train epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "                #print('average',np.mean(scores))\n",
    "\n",
    "            if e%evaluate_dev==0:\n",
    "                total_loss = 0\n",
    "                total_acc = 0\n",
    "                num_batches = 0\n",
    "                for ii, (x, y) in enumerate(batch_generator(x_dev, y_dev, batch_size), 1):\n",
    "                    feed_dict = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: 1.0}\n",
    "                    loss, accuracy = sess.run([cnn.loss, cnn.accuracy],feed_dict)\n",
    "                    total_loss += loss*len(x)\n",
    "                    total_acc += accuracy*len(x)\n",
    "                    num_batches += 1\n",
    "                avg_loss = total_loss/(num_batches*batch_size)\n",
    "                avg_acc = total_acc/(num_batches*batch_size)\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "                print(\"\\t\\tDev epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "            if e%time_print == 0:\n",
    "                end = time.time()\n",
    "                print(\"\\t\\t\\t\\t    Time taken for\",e,\"epochs = \", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying smaller filter size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(object):\n",
    "    \"\"\"\n",
    "    A CNN for text classification.\n",
    "    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "      self, sequence_length, num_classes, vocab_size,\n",
    "      embedding_size, filter_sizes, num_filters, l2_reg_lambda=0.0):\n",
    "\n",
    "        # Placeholders for input, output and dropout\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, num_classes], name=\"input_y\")\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "        # Keeping track of l2 regularization loss (optional)\n",
    "        l2_loss = tf.constant(0.0)\n",
    "\n",
    "        # Embedding layer\n",
    "        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "            self.W = tf.Variable(\n",
    "                tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0),\n",
    "                name=\"W\")\n",
    "            self.embedded_chars = tf.nn.embedding_lookup(self.W, self.input_x)\n",
    "            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n",
    "\n",
    "        # Create a convolution + maxpool layer for each filter size\n",
    "        pooled_outputs = []\n",
    "        for i, filter_size in enumerate(filter_sizes):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "                # Convolution Layer\n",
    "                filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "                Wname = \"w_%d\"%filter_size\n",
    "                W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "                \n",
    "                b = tf.Variable(tf.constant(0.0, shape=[num_filters]), name=\"b\")\n",
    "                conv = tf.nn.conv2d(\n",
    "                    self.embedded_chars_expanded,\n",
    "                    W,\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding=\"VALID\",\n",
    "                    name=\"conv\")\n",
    "                \n",
    "                # Apply nonlinearity\n",
    "                h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "                \n",
    "                # Maxpooling over the outputs\n",
    "                pooled = tf.nn.max_pool(\n",
    "                    h,\n",
    "                    ksize=[1, sequence_length - filter_size + 1, 1, 1],\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding='VALID',\n",
    "                    name=\"pool\")\n",
    "                pooled_outputs.append(pooled)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        num_filters_total = num_filters * len(filter_sizes)\n",
    "        \n",
    "        #the line below differs from the tutorial, but is necessary based on changes to Tensorflow\n",
    "        self.h_pool = tf.concat(pooled_outputs, 3)\n",
    "\n",
    "        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
    "\n",
    "        # Add dropout\n",
    "        with tf.name_scope(\"dropout\"):\n",
    "            self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keep_prob)\n",
    "\n",
    "        # Final (unnormalized) scores and predictions\n",
    "        with tf.name_scope(\"output\"):\n",
    "            W = tf.get_variable(\n",
    "                \"W\",\n",
    "                shape=[num_filters_total, num_classes],\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.Variable(tf.constant(0.0, shape=[num_classes]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            self.scores = tf.nn.xw_plus_b(self.h_drop, W, b, name=\"scores\")\n",
    "            print(\"scores shape:\", self.scores.shape)\n",
    "            self.predictions = tf.argmax(self.scores, 1, name=\"predictions\")\n",
    "\n",
    "        # Calculate mean cross-entropy loss\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss\n",
    "\n",
    "        # Accuracy\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            \n",
    "            #correct_predictions = tf.equal(tf.cast(self.predictions,tf.float32), self.input_y)\n",
    "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n",
    "\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")\n",
    "            \n",
    "        with tf.name_scope('train'):\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(ids, labels, batch_size=100):\n",
    "            \n",
    "    n_batches = len(ids)//batch_size\n",
    "    ids, labels = ids[:n_batches*batch_size], labels[:n_batches*batch_size]\n",
    "    shuffle = np.random.permutation(np.arange(n_batches*batch_size))\n",
    "    ids, labels = ids[shuffle], labels[shuffle]\n",
    "\n",
    "    \n",
    "    for ii in range(0, len(ids), batch_size):\n",
    "        yield ids[ii:ii+batch_size], labels[ii:ii+batch_size]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /home/kierstenhenderson/Final_project/runs/cnn\n",
      "\n",
      "scores shape: (?, 2)\n",
      "WARNING:tensorflow:From <ipython-input-14-1213db3c714d>:83: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "completed cnn creation\n",
      "# batches = 5067\n",
      "Train epoch 0, average loss 0.48908, average accuracy 0.934222,\n",
      "\t\tDev epoch 0, average loss 0.40466, average accuracy 0.952218,\n",
      "\t\t\t\t    Time taken for 0 epochs =  529.6132485866547\n",
      "Train epoch 1, average loss 0.579214, average accuracy 0.942159,\n",
      "\t\tDev epoch 1, average loss 0.528759, average accuracy 0.949918,\n",
      "Train epoch 2, average loss 0.598762, average accuracy 0.93853,\n",
      "\t\tDev epoch 2, average loss 0.810308, average accuracy 0.947499,\n",
      "Train epoch 3, average loss 0.616179, average accuracy 0.937016,\n",
      "\t\tDev epoch 3, average loss 1.45503, average accuracy 0.942305,\n",
      "Train epoch 4, average loss 0.594433, average accuracy 0.934919,\n",
      "\t\tDev epoch 4, average loss 1.85442, average accuracy 0.943396,\n",
      "Train epoch 5, average loss 0.760009, average accuracy 0.929051,\n",
      "\t\tDev epoch 5, average loss 2.3004, average accuracy 0.922728,\n",
      "Train epoch 6, average loss 0.649711, average accuracy 0.923642,\n",
      "\t\tDev epoch 6, average loss 2.30528, average accuracy 0.926831,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f1b0062ce271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_keep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mtotal_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Actual training loop:\n",
    "embed_dim = 300 \n",
    "filter_sizes= [3,4,5]\n",
    "num_filters = 100\n",
    "l2_reg_lambda = 0\n",
    "learning_rate = 0.01\n",
    "keep_prob = 0.5\n",
    "evaluate_train = 1 # of epochs at which to print test accuracy\n",
    "evaluate_dev = 1 # of epochs at which to estimate and print dev accuracy\n",
    "time_print = 12 # of epochs at which to print time taken\n",
    "num_classes = 2\n",
    "num_epochs = 10\n",
    "\n",
    "num_checkpoints = 1\n",
    "batch_size = 64\n",
    "\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", \"cnn\"))\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        cnn = TextCNN(sequence_length=x_train.shape[1], num_classes=num_classes, vocab_size=V, embedding_size=embed_dim, filter_sizes= filter_sizes, \n",
    "                      num_filters=num_filters, l2_reg_lambda=l2_reg_lambda)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('completed cnn creation')\n",
    "\n",
    "        # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "        checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=num_checkpoints)\n",
    "\n",
    "        print('# batches =', len(x_train)//batch_size)\n",
    "        start = time.time()\n",
    "        for e in range(num_epochs):\n",
    "                    \n",
    "            #sum_scores = np.zeros((batch_size*(len(x_train)//batch_size),1))\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            for i, (x, y) in enumerate(batch_generator(x_train, y_train, batch_size), 1):\n",
    "                feed = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: keep_prob}\n",
    "                _, scores, loss, accuracy = sess.run([cnn.optimizer,cnn.scores,cnn.loss, cnn.accuracy],feed_dict = feed)\n",
    "                total_loss += loss*len(x)\n",
    "                total_acc += accuracy*len(x)\n",
    "                \n",
    "                #sum_scores[i*batch_size:(i+1)*batch_size,:] = scores\n",
    "                #print(np.mean(sum_scores))\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "            if e%evaluate_train==0:\n",
    "                avg_loss = total_loss/(batch_size*(len(x_train)//batch_size))\n",
    "                avg_acc = total_acc/(batch_size*(len(x_train)//batch_size))\n",
    "                print(\"Train epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "                #print('average',np.mean(scores))\n",
    "\n",
    "            if e%evaluate_dev==0:\n",
    "                total_loss = 0\n",
    "                total_acc = 0\n",
    "                num_batches = 0\n",
    "                for ii, (x, y) in enumerate(batch_generator(x_dev, y_dev, batch_size), 1):\n",
    "                    feed_dict = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: 1.0}\n",
    "                    loss, accuracy = sess.run([cnn.loss, cnn.accuracy],feed_dict)\n",
    "                    total_loss += loss*len(x)\n",
    "                    total_acc += accuracy*len(x)\n",
    "                    num_batches += 1\n",
    "                avg_loss = total_loss/(num_batches*batch_size)\n",
    "                avg_acc = total_acc/(num_batches*batch_size)\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "                print(\"\\t\\tDev epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "            if e%time_print == 0:\n",
    "                end = time.time()\n",
    "                print(\"\\t\\t\\t\\t    Time taken for\",e,\"epochs = \", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter size 100, learning rate 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /home/kierstenhenderson/Final_project/runs/cnn\n",
      "\n",
      "scores shape: (?, 2)\n",
      "completed cnn creation\n",
      "# batches = 5067\n",
      "Train epoch 0, average loss 0.549724, average accuracy 0.854965,\n",
      "\t\tDev epoch 0, average loss 0.145365, average accuracy 0.948752,\n",
      "\t\t\t\t    Time taken for 0 epochs =  482.00134205818176\n",
      "Train epoch 1, average loss 0.167735, average accuracy 0.937562,\n",
      "\t\tDev epoch 1, average loss 0.108812, average accuracy 0.960921,\n",
      "Train epoch 2, average loss 0.114123, average accuracy 0.958065,\n",
      "\t\tDev epoch 2, average loss 0.0856902, average accuracy 0.969301,\n",
      "Train epoch 3, average loss 0.0859665, average accuracy 0.968284,\n",
      "\t\tDev epoch 3, average loss 0.0727051, average accuracy 0.97362,\n",
      "Train epoch 4, average loss 0.0683465, average accuracy 0.975016,\n",
      "\t\tDev epoch 4, average loss 0.0644522, average accuracy 0.976654,\n",
      "Train epoch 5, average loss 0.0554454, average accuracy 0.979827,\n",
      "\t\tDev epoch 5, average loss 0.0598681, average accuracy 0.978285,\n",
      "Train epoch 6, average loss 0.0459915, average accuracy 0.983305,\n",
      "\t\tDev epoch 6, average loss 0.0567078, average accuracy 0.979732,\n",
      "Train epoch 7, average loss 0.0390715, average accuracy 0.98596,\n",
      "\t\tDev epoch 7, average loss 0.0549056, average accuracy 0.980596,\n",
      "Train epoch 8, average loss 0.0331047, average accuracy 0.988131,\n",
      "\t\tDev epoch 8, average loss 0.0547061, average accuracy 0.98093,\n",
      "Train epoch 9, average loss 0.0284283, average accuracy 0.989728,\n",
      "\t\tDev epoch 9, average loss 0.0541522, average accuracy 0.981719,\n",
      "Train epoch 10, average loss 0.0243189, average accuracy 0.991276,\n",
      "\t\tDev epoch 10, average loss 0.0542025, average accuracy 0.981848,\n",
      "Train epoch 11, average loss 0.0204405, average accuracy 0.992821,\n",
      "\t\tDev epoch 11, average loss 0.0557929, average accuracy 0.98214,\n",
      "Train epoch 12, average loss 0.0176603, average accuracy 0.993712,\n",
      "\t\tDev epoch 12, average loss 0.0576661, average accuracy 0.982323,\n",
      "\t\t\t\t    Time taken for 12 epochs =  6406.886142492294\n",
      "Train epoch 13, average loss 0.0146781, average accuracy 0.994696,\n",
      "\t\tDev epoch 13, average loss 0.060485, average accuracy 0.982356,\n",
      "Train epoch 14, average loss 0.0127134, average accuracy 0.99568,\n",
      "\t\tDev epoch 14, average loss 0.0625263, average accuracy 0.982075,\n"
     ]
    }
   ],
   "source": [
    "#Actual training loop:\n",
    "embed_dim = 300 \n",
    "filter_sizes= [3,4,5]\n",
    "num_filters = 100\n",
    "l2_reg_lambda = 0\n",
    "learning_rate = 0.0001\n",
    "keep_prob = 0.5\n",
    "evaluate_train = 1 # of epochs at which to print test accuracy\n",
    "evaluate_dev = 1 # of epochs at which to estimate and print dev accuracy\n",
    "time_print = 12 # of epochs at which to print time taken\n",
    "num_classes = 2\n",
    "num_epochs = 15\n",
    "\n",
    "num_checkpoints = 1\n",
    "batch_size = 64\n",
    "\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", \"cnn\"))\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        cnn = TextCNN(sequence_length=x_train.shape[1], num_classes=num_classes, vocab_size=V, embedding_size=embed_dim, filter_sizes= filter_sizes, \n",
    "                      num_filters=num_filters, l2_reg_lambda=l2_reg_lambda)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('completed cnn creation')\n",
    "\n",
    "        # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "        checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        \n",
    "        print('# batches =', len(x_train)//batch_size)\n",
    "        start = time.time()\n",
    "        for e in range(num_epochs):\n",
    "                    \n",
    "            #sum_scores = np.zeros((batch_size*(len(x_train)//batch_size),1))\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            for i, (x, y) in enumerate(batch_generator(x_train, y_train, batch_size), 1):\n",
    "                feed = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: keep_prob}\n",
    "                _, scores, loss, accuracy = sess.run([cnn.optimizer,cnn.scores,cnn.loss, cnn.accuracy],feed_dict = feed)\n",
    "                total_loss += loss*len(x)\n",
    "                total_acc += accuracy*len(x)\n",
    "                \n",
    "                #sum_scores[i*batch_size:(i+1)*batch_size,:] = scores\n",
    "                #print(np.mean(sum_scores))\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "            if e%evaluate_train==0:\n",
    "                avg_loss = total_loss/(batch_size*(len(x_train)//batch_size))\n",
    "                avg_acc = total_acc/(batch_size*(len(x_train)//batch_size))\n",
    "                print(\"Train epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "                #print('average',np.mean(scores))\n",
    "\n",
    "            if e%evaluate_dev==0:\n",
    "                total_loss = 0\n",
    "                total_acc = 0\n",
    "                num_batches = 0\n",
    "                for ii, (x, y) in enumerate(batch_generator(x_dev, y_dev, batch_size), 1):\n",
    "                    feed_dict = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: 1.0}\n",
    "                    loss, accuracy = sess.run([cnn.loss, cnn.accuracy],feed_dict)\n",
    "                    total_loss += loss*len(x)\n",
    "                    total_acc += accuracy*len(x)\n",
    "                    num_batches += 1\n",
    "                avg_loss = total_loss/(num_batches*batch_size)\n",
    "                avg_acc = total_acc/(num_batches*batch_size)\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "                print(\"\\t\\tDev epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "            \n",
    "            #save_path = saver.save(sess, \"./runs/cnn/checkpoints/my_training_final_model.ckpt\")\n",
    "\n",
    "            if e%time_print == 0:\n",
    "                end = time.time()\n",
    "                print(\"\\t\\t\\t\\t    Time taken for\",e,\"epochs = \", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model created with 100 filters, learning rate 0.0001 as: my_training_final_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /home/kierstenhenderson/Final_project/runs/cnn\n",
      "\n",
      "scores shape: (?, 2)\n",
      "completed cnn creation\n",
      "# batches = 5067\n",
      "Train epoch 0, average loss 0.523222, average accuracy 0.859162,\n",
      "\t\tDev epoch 0, average loss 0.142759, average accuracy 0.94941,\n",
      "\t\t\t\t    Time taken for 0 epochs =  484.31138467788696\n",
      "Train epoch 1, average loss 0.164819, average accuracy 0.938863,\n",
      "\t\tDev epoch 1, average loss 0.1079, average accuracy 0.961396,\n",
      "Train epoch 2, average loss 0.112586, average accuracy 0.958716,\n",
      "\t\tDev epoch 2, average loss 0.08599, average accuracy 0.969171,\n",
      "Train epoch 3, average loss 0.0857723, average accuracy 0.968716,\n",
      "\t\tDev epoch 3, average loss 0.0737298, average accuracy 0.973296,\n",
      "Train epoch 4, average loss 0.0681073, average accuracy 0.974754,\n",
      "\t\tDev epoch 4, average loss 0.0657978, average accuracy 0.976179,\n",
      "Train epoch 5, average loss 0.0564885, average accuracy 0.97946,\n",
      "\t\tDev epoch 5, average loss 0.0607796, average accuracy 0.97781,\n",
      "Train epoch 6, average loss 0.0467574, average accuracy 0.983,\n",
      "\t\tDev epoch 6, average loss 0.0583679, average accuracy 0.979105,\n",
      "Train epoch 7, average loss 0.0393293, average accuracy 0.985843,\n",
      "\t\tDev epoch 7, average loss 0.05629, average accuracy 0.980347,\n",
      "Train epoch 8, average loss 0.0338328, average accuracy 0.987659,\n",
      "\t\tDev epoch 8, average loss 0.0560641, average accuracy 0.980909,\n",
      "Train epoch 9, average loss 0.0282768, average accuracy 0.989858,\n",
      "\t\tDev epoch 9, average loss 0.0559797, average accuracy 0.981384,\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 300 \n",
    "filter_sizes= [3,4,5]\n",
    "num_filters = 100\n",
    "l2_reg_lambda = 0\n",
    "learning_rate = 0.0001\n",
    "keep_prob = 0.5\n",
    "evaluate_train = 1 # of epochs at which to print test accuracy\n",
    "evaluate_dev = 1 # of epochs at which to estimate and print dev accuracy\n",
    "time_print = 12 # of epochs at which to print time taken\n",
    "num_classes = 2\n",
    "num_epochs = 10\n",
    "\n",
    "num_checkpoints = 1\n",
    "batch_size = 64\n",
    "\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", \"cnn\"))\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        cnn = TextCNN(sequence_length=x_train.shape[1], num_classes=num_classes, vocab_size=V, embedding_size=embed_dim, filter_sizes= filter_sizes, \n",
    "                      num_filters=num_filters, l2_reg_lambda=l2_reg_lambda)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('completed cnn creation')\n",
    "\n",
    "        # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "        checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        print('# batches =', len(x_train)//batch_size)\n",
    "        start = time.time()\n",
    "        for e in range(num_epochs):\n",
    "                    \n",
    "            #sum_scores = np.zeros((batch_size*(len(x_train)//batch_size),1))\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            \n",
    "            for i, (x, y) in enumerate(batch_generator(x_train, y_train, batch_size), 1):\n",
    "                feed = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: keep_prob}\n",
    "                _, scores, loss, accuracy = sess.run([cnn.optimizer,cnn.scores,cnn.loss, cnn.accuracy],feed_dict = feed)\n",
    "                total_loss += loss*len(x)\n",
    "                total_acc += accuracy*len(x)\n",
    "                \n",
    "                #sum_scores[i*batch_size:(i+1)*batch_size,:] = scores\n",
    "                #print(np.mean(sum_scores))\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "            if e%evaluate_train==0:\n",
    "                avg_loss = total_loss/(batch_size*(len(x_train)//batch_size))\n",
    "                avg_acc = total_acc/(batch_size*(len(x_train)//batch_size))\n",
    "                print(\"Train epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "                #print('average',np.mean(scores))\n",
    "            save_path = saver.save(sess, \"./runs/cnn/checkpoints/my_training_final_model_2.ckpt\")\n",
    "            \n",
    "            if e%evaluate_dev==0:\n",
    "                total_loss = 0\n",
    "                total_acc = 0\n",
    "                num_batches = 0\n",
    "                for ii, (x, y) in enumerate(batch_generator(x_dev, y_dev, batch_size), 1):\n",
    "                    feed_dict = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: 1.0}\n",
    "                    loss, accuracy = sess.run([cnn.loss, cnn.accuracy],feed_dict)\n",
    "                    total_loss += loss*len(x)\n",
    "                    total_acc += accuracy*len(x)\n",
    "                    num_batches += 1\n",
    "                avg_loss = total_loss/(num_batches*batch_size)\n",
    "                avg_acc = total_acc/(num_batches*batch_size)\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "                print(\"\\t\\tDev epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "                \n",
    "                \n",
    "            \n",
    "            if e%time_print == 0:\n",
    "                end = time.time()\n",
    "                print(\"\\t\\t\\t\\t    Time taken for\",e,\"epochs = \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./runs/cnn/checkpoints/my_training_final_model_2.ckpt\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    session_conf = tf.ConfigProto()\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        # Load the saved meta graph and restore variables\n",
    "        saver = tf.train.import_meta_graph(\"./runs/cnn/checkpoints/my_training_final_model_2.ckpt.meta\")\n",
    "        saver.restore(sess, \"./runs/cnn/checkpoints/my_training_final_model_2.ckpt\")\n",
    "        # Get the placeholders from the graph by name\n",
    "        input_x = graph.get_operation_by_name(\"input_x\").outputs[0]\n",
    "        # input_y = graph.get_operation_by_name(\"input_y\").outputs[0]\n",
    "        dropout_keep_prob = graph.get_operation_by_name(\"dropout_keep_prob\").outputs[0]\n",
    "\n",
    "        # Tensors we want to evaluate\n",
    "        predictions = graph.get_operation_by_name(\"output/predictions\").outputs[0]\n",
    "\n",
    "        \n",
    "        test_predictions = sess.run(predictions, {input_x: x_test, dropout_keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46331"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_class_test = y_test[:,1]\n",
    "actual_class_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test examples: 46331\n",
      "Accuracy: 0.981978\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = float(sum(test_predictions == actual_class_test))\n",
    "print(\"Total number of test examples: {}\".format(len(actual_class_test)))\n",
    "print(\"Accuracy: {:g}\".format(correct_predictions/float(len(actual_class_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.DataFrame({\"text_example\": test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>452670</th>\n",
       "      <td>spring arrives thursday afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257774</th>\n",
       "      <td>older women are most vulnerable to cervical cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8829</th>\n",
       "      <td>why did the run-on sentence take a pregnancy test? because its period came too late.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411172</th>\n",
       "      <td>tv review: 'rosemary's baby'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153671</th>\n",
       "      <td>i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      text_example\n",
       "452670  spring arrives thursday afternoon                                                                         \n",
       "257774  older women are most vulnerable to cervical cancer                                                        \n",
       "8829    why did the run-on sentence take a pregnancy test? because its period came too late.                      \n",
       "411172  tv review: 'rosemary's baby'                                                                              \n",
       "153671  i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spring arrives thursday afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>older women are most vulnerable to cervical cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did the run-on sentence take a pregnancy test? because its period came too late.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tv review: 'rosemary's baby'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text_example\n",
       "0  spring arrives thursday afternoon                                                                         \n",
       "1  older women are most vulnerable to cervical cancer                                                        \n",
       "2  why did the run-on sentence take a pregnancy test? because its period came too late.                      \n",
       "3  tv review: 'rosemary's baby'                                                                              \n",
       "4  i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text.reset_index(drop=True)\n",
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   funny  not_funny\n",
       "0  0      1        \n",
       "1  0      1        \n",
       "2  1      0        \n",
       "3  0      1        \n",
       "4  1      0        "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_label = test_label.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   funny  not_funny\n",
       "0  0      1        \n",
       "1  0      1        \n",
       "2  1      0        \n",
       "3  0      1        \n",
       "4  1      0        "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = text.merge(test_label, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_example</th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spring arrives thursday afternoon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>older women are most vulnerable to cervical cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did the run-on sentence take a pregnancy test? because its period came too late.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tv review: 'rosemary's baby'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text_example  \\\n",
       "0  spring arrives thursday afternoon                                                                            \n",
       "1  older women are most vulnerable to cervical cancer                                                           \n",
       "2  why did the run-on sentence take a pregnancy test? because its period came too late.                         \n",
       "3  tv review: 'rosemary's baby'                                                                                 \n",
       "4  i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo   \n",
       "\n",
       "   funny  not_funny  \n",
       "0  0      1          \n",
       "1  0      1          \n",
       "2  1      0          \n",
       "3  0      1          \n",
       "4  1      0          "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = pd.Series(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.merge(test_predictions.to_frame(), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_example</th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spring arrives thursday afternoon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>older women are most vulnerable to cervical cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did the run-on sentence take a pregnancy test? because its period came too late.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tv review: 'rosemary's baby'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text_example  \\\n",
       "0  spring arrives thursday afternoon                                                                            \n",
       "1  older women are most vulnerable to cervical cancer                                                           \n",
       "2  why did the run-on sentence take a pregnancy test? because its period came too late.                         \n",
       "3  tv review: 'rosemary's baby'                                                                                 \n",
       "4  i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo   \n",
       "\n",
       "   funny  not_funny  0  \n",
       "0  0      1          1  \n",
       "1  0      1          1  \n",
       "2  1      0          0  \n",
       "3  0      1          1  \n",
       "4  1      0          0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns = ['text', 'funny', 'not_funny', 'predicted_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spring arrives thursday afternoon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>older women are most vulnerable to cervical cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did the run-on sentence take a pregnancy test? because its period came too late.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tv review: 'rosemary's baby'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                         text  \\\n",
       "0  spring arrives thursday afternoon                                                                            \n",
       "1  older women are most vulnerable to cervical cancer                                                           \n",
       "2  why did the run-on sentence take a pregnancy test? because its period came too late.                         \n",
       "3  tv review: 'rosemary's baby'                                                                                 \n",
       "4  i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo   \n",
       "\n",
       "   funny  not_funny  predicted_class  \n",
       "0  0      1          1                \n",
       "1  0      1          1                \n",
       "2  1      0          0                \n",
       "3  0      1          1                \n",
       "4  1      0          0                "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['correct_prediction'] = df_test.not_funny == df_test.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>correct_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spring arrives thursday afternoon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>older women are most vulnerable to cervical cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did the run-on sentence take a pregnancy test? because its period came too late.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tv review: 'rosemary's baby'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                         text  \\\n",
       "0  spring arrives thursday afternoon                                                                            \n",
       "1  older women are most vulnerable to cervical cancer                                                           \n",
       "2  why did the run-on sentence take a pregnancy test? because its period came too late.                         \n",
       "3  tv review: 'rosemary's baby'                                                                                 \n",
       "4  i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo   \n",
       "\n",
       "   funny  not_funny  predicted_class  correct_prediction  \n",
       "0  0      1          1                True                \n",
       "1  0      1          1                True                \n",
       "2  1      0          0                True                \n",
       "3  0      1          1                True                \n",
       "4  1      0          0                True                "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9819775096587597"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.correct_prediction.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test.to_csv(\"./evaluating_model_results/base_cnn_100filters_0.0001LR.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model created with 256 filters, Learning Rate 0.0001 as my_training_final_model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /home/kierstenhenderson/Final_project/runs/cnn\n",
      "\n",
      "scores shape: (?, 2)\n",
      "completed cnn creation\n",
      "# batches = 5067\n",
      "Train epoch 0, average loss 0.460008, average accuracy 0.880372,\n",
      "\t\tDev epoch 0, average loss 0.131682, average accuracy 0.954,\n",
      "\t\t\t\t    Time taken for 0 epochs =  618.1741096973419\n",
      "Train epoch 1, average loss 0.148801, average accuracy 0.945339,\n",
      "\t\tDev epoch 1, average loss 0.0972129, average accuracy 0.964873,\n",
      "Train epoch 2, average loss 0.100837, average accuracy 0.963273,\n",
      "\t\tDev epoch 2, average loss 0.0782043, average accuracy 0.971935,\n",
      "Train epoch 3, average loss 0.0756959, average accuracy 0.972429,\n",
      "\t\tDev epoch 3, average loss 0.0684272, average accuracy 0.975369,\n",
      "Train epoch 4, average loss 0.0592153, average accuracy 0.978331,\n",
      "\t\tDev epoch 4, average loss 0.061996, average accuracy 0.977961,\n",
      "Train epoch 5, average loss 0.0472042, average accuracy 0.982778,\n",
      "\t\tDev epoch 5, average loss 0.0583225, average accuracy 0.979678,\n",
      "Train epoch 6, average loss 0.0379949, average accuracy 0.986136,\n",
      "\t\tDev epoch 6, average loss 0.0575558, average accuracy 0.980315,\n",
      "Train epoch 7, average loss 0.030904, average accuracy 0.98884,\n",
      "\t\tDev epoch 7, average loss 0.0566834, average accuracy 0.981211,\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 300 #use when not using pre-trained embeddings\n",
    "filter_sizes= [3,4,5]\n",
    "num_filters = 256\n",
    "l2_reg_lambda = 0\n",
    "learning_rate = 0.0001\n",
    "keep_prob = 0.5\n",
    "evaluate_train = 1 # of epochs at which to print test accuracy\n",
    "evaluate_dev = 1 # of epochs at which to estimate and print dev accuracy\n",
    "time_print = 12 # of epochs at which to print time taken\n",
    "num_classes = 2\n",
    "num_epochs = 8\n",
    "\n",
    "num_checkpoints = 1\n",
    "batch_size = 64\n",
    "\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", \"cnn\"))\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        cnn = TextCNN(sequence_length=x_train.shape[1], num_classes=num_classes, vocab_size=V, embedding_size=embed_dim, filter_sizes= filter_sizes, \n",
    "                      num_filters=num_filters, l2_reg_lambda=l2_reg_lambda)\n",
    "       \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('completed cnn creation')\n",
    "\n",
    "        # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "        checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        #saver = tf.train.Saver(tf.global_variables(), max_to_keep=num_checkpoints)\n",
    "\n",
    "        # Write vocabulary\n",
    "        ## vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "\n",
    "        print('# batches =', len(x_train)//batch_size)\n",
    "        start = time.time()\n",
    "        for e in range(num_epochs):\n",
    "                    \n",
    "            #sum_scores = np.zeros((batch_size*(len(x_train)//batch_size),1))\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            \n",
    "            for i, (x, y) in enumerate(batch_generator(x_train, y_train, batch_size), 1):\n",
    "                feed = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: keep_prob}\n",
    "                _, scores, loss, accuracy = sess.run([cnn.optimizer,cnn.scores,cnn.loss, cnn.accuracy],feed_dict = feed)\n",
    "                total_loss += loss*len(x)\n",
    "                total_acc += accuracy*len(x)\n",
    "                \n",
    "                #sum_scores[i*batch_size:(i+1)*batch_size,:] = scores\n",
    "                #print(np.mean(sum_scores))\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "            if e%evaluate_train==0:\n",
    "                avg_loss = total_loss/(batch_size*(len(x_train)//batch_size))\n",
    "                avg_acc = total_acc/(batch_size*(len(x_train)//batch_size))\n",
    "                print(\"Train epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "                #print('average',np.mean(scores))\n",
    "            save_path = saver.save(sess, \"./runs/cnn/checkpoints/my_training_final_model_3.ckpt\")\n",
    "            \n",
    "            if e%evaluate_dev==0:\n",
    "                total_loss = 0\n",
    "                total_acc = 0\n",
    "                num_batches = 0\n",
    "                for ii, (x, y) in enumerate(batch_generator(x_dev, y_dev, batch_size), 1):\n",
    "                    feed_dict = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: 1.0}\n",
    "                    loss, accuracy = sess.run([cnn.loss, cnn.accuracy],feed_dict)\n",
    "                    total_loss += loss*len(x)\n",
    "                    total_acc += accuracy*len(x)\n",
    "                    num_batches += 1\n",
    "                avg_loss = total_loss/(num_batches*batch_size)\n",
    "                avg_acc = total_acc/(num_batches*batch_size)\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "                print(\"\\t\\tDev epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))    \n",
    "            \n",
    "            if e%time_print == 0:\n",
    "                end = time.time()\n",
    "                print(\"\\t\\t\\t\\t    Time taken for\",e,\"epochs = \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./runs/cnn/checkpoints/my_training_final_model_3.ckpt\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    session_conf = tf.ConfigProto()\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        # Load the saved meta graph and restore variables\n",
    "        saver = tf.train.import_meta_graph(\"./runs/cnn/checkpoints/my_training_final_model_3.ckpt.meta\")\n",
    "        saver.restore(sess, \"./runs/cnn/checkpoints/my_training_final_model_3.ckpt\")\n",
    "        # Get the placeholders from the graph by name\n",
    "        input_x = graph.get_operation_by_name(\"input_x\").outputs[0]\n",
    "        # input_y = graph.get_operation_by_name(\"input_y\").outputs[0]\n",
    "        dropout_keep_prob = graph.get_operation_by_name(\"dropout_keep_prob\").outputs[0]\n",
    "\n",
    "        # Tensors we want to evaluate\n",
    "        predictions = graph.get_operation_by_name(\"output/predictions\").outputs[0]\n",
    "\n",
    "        \n",
    "        test_predictions = sess.run(predictions, {input_x: x_test, dropout_keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_class_test = y_test[:,1]\n",
    "actual_class_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test examples: 46331\n",
      "Accuracy: 0.982021\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = float(sum(test_predictions == actual_class_test))\n",
    "print(\"Total number of test examples: {}\".format(len(actual_class_test)))\n",
    "print(\"Accuracy: {:g}\".format(correct_predictions/float(len(actual_class_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = pd.DataFrame({\"text_example\": test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spring arrives thursday afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>older women are most vulnerable to cervical cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did the run-on sentence take a pregnancy test? because its period came too late.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tv review: 'rosemary's baby'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text_example\n",
       "0  spring arrives thursday afternoon                                                                         \n",
       "1  older women are most vulnerable to cervical cancer                                                        \n",
       "2  why did the run-on sentence take a pregnancy test? because its period came too late.                      \n",
       "3  tv review: 'rosemary's baby'                                                                              \n",
       "4  i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text.reset_index(drop=True)\n",
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_label.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   funny  not_funny\n",
       "0  0      1        \n",
       "1  0      1        \n",
       "2  1      0        \n",
       "3  0      1        \n",
       "4  1      0        "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = text.merge(test_label, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_example</th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spring arrives thursday afternoon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>older women are most vulnerable to cervical cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did the run-on sentence take a pregnancy test? because its period came too late.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tv review: 'rosemary's baby'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text_example  \\\n",
       "0  spring arrives thursday afternoon                                                                            \n",
       "1  older women are most vulnerable to cervical cancer                                                           \n",
       "2  why did the run-on sentence take a pregnancy test? because its period came too late.                         \n",
       "3  tv review: 'rosemary's baby'                                                                                 \n",
       "4  i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo   \n",
       "\n",
       "   funny  not_funny  \n",
       "0  0      1          \n",
       "1  0      1          \n",
       "2  1      0          \n",
       "3  0      1          \n",
       "4  1      0          "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = pd.Series(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.merge(test_predictions.to_frame(), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_example</th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spring arrives thursday afternoon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>older women are most vulnerable to cervical cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did the run-on sentence take a pregnancy test? because its period came too late.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tv review: 'rosemary's baby'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text_example  \\\n",
       "0  spring arrives thursday afternoon                                                                            \n",
       "1  older women are most vulnerable to cervical cancer                                                           \n",
       "2  why did the run-on sentence take a pregnancy test? because its period came too late.                         \n",
       "3  tv review: 'rosemary's baby'                                                                                 \n",
       "4  i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo   \n",
       "\n",
       "   funny  not_funny  0  \n",
       "0  0      1          1  \n",
       "1  0      1          1  \n",
       "2  1      0          0  \n",
       "3  0      1          1  \n",
       "4  1      0          0  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns = ['text', 'funny', 'not_funny', 'predicted_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spring arrives thursday afternoon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>older women are most vulnerable to cervical cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did the run-on sentence take a pregnancy test? because its period came too late.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tv review: 'rosemary's baby'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                         text  \\\n",
       "0  spring arrives thursday afternoon                                                                            \n",
       "1  older women are most vulnerable to cervical cancer                                                           \n",
       "2  why did the run-on sentence take a pregnancy test? because its period came too late.                         \n",
       "3  tv review: 'rosemary's baby'                                                                                 \n",
       "4  i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo   \n",
       "\n",
       "   funny  not_funny  predicted_class  \n",
       "0  0      1          1                \n",
       "1  0      1          1                \n",
       "2  1      0          0                \n",
       "3  0      1          1                \n",
       "4  1      0          0                "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['correct_prediction'] = df_test.not_funny == df_test.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>correct_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spring arrives thursday afternoon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>older women are most vulnerable to cervical cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did the run-on sentence take a pregnancy test? because its period came too late.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tv review: 'rosemary's baby'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                         text  \\\n",
       "0  spring arrives thursday afternoon                                                                            \n",
       "1  older women are most vulnerable to cervical cancer                                                           \n",
       "2  why did the run-on sentence take a pregnancy test? because its period came too late.                         \n",
       "3  tv review: 'rosemary's baby'                                                                                 \n",
       "4  i was at the natural history museum and i saw the neanderthal exhibit. those guys were buff studs. no homo   \n",
       "\n",
       "   funny  not_funny  predicted_class  correct_prediction  \n",
       "0  0      1          1                True                \n",
       "1  0      1          1                True                \n",
       "2  1      0          0                True                \n",
       "3  0      1          1                True                \n",
       "4  1      0          0                True                "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820206773002957"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.correct_prediction.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"./evaluating_model_results/base_cnn_256filters_0.0001LR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Dataset2 with model made with Dataset 1: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First applied model with 100 filters, it worked better than the one created with 256 filters so we used it to perform our Analysis of Dataset 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/dataset2_crowdtruth_working.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>left luggage , also luggage storage or bag sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>their name comes from the title of the the fla...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the lyside sulphur can grow from egg to adult ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>istanbul suicide bomber entered turkey as a m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>both describe god as the one divine person , j...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  funny  not_funny\n",
       "0  left luggage , also luggage storage or bag sto...      0          1\n",
       "1  their name comes from the title of the the fla...      0          1\n",
       "2  the lyside sulphur can grow from egg to adult ...      0          1\n",
       "3   istanbul suicide bomber entered turkey as a m...      0          1\n",
       "4  both describe god as the one divine person , j...      0          1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "Y_1 = df['funny']\n",
    "Y_2 = df['not_funny']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10868"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame({\"funny\": Y_1.values,\"not_funny\": Y_2.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   funny  not_funny\n",
       "0      0          1\n",
       "1      0          1\n",
       "2      0          1\n",
       "3      0          1\n",
       "4      0          1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset2_data (10868,)\n"
     ]
    }
   ],
   "source": [
    "dataset2_data, dataset2_label = X, Y\n",
    "print('dataset2_data', dataset2_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = processor.transform(dataset2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10868, 34)\n",
      "(10868, 2)\n"
     ]
    }
   ],
   "source": [
    "x_dataset2 = np.array(list(dataset2))\n",
    "y_dataset2 = np.array(dataset2_label).astype(int)\n",
    "\n",
    "print(x_dataset2.shape)\n",
    "print(y_dataset2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2 predictions with model to test scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./runs/cnn/checkpoints/my_training_final_model_2.ckpt\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    session_conf = tf.ConfigProto()\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        # Load the saved meta graph and restore variables\n",
    "        saver = tf.train.import_meta_graph(\"./runs/cnn/checkpoints/my_training_final_model_2.ckpt.meta\")\n",
    "        saver.restore(sess, \"./runs/cnn/checkpoints/my_training_final_model_2.ckpt\")\n",
    "        # Get the placeholders from the graph by name\n",
    "        input_x = graph.get_operation_by_name(\"input_x\").outputs[0]\n",
    "        # input_y = graph.get_operation_by_name(\"input_y\").outputs[0]\n",
    "        dropout_keep_prob = graph.get_operation_by_name(\"dropout_keep_prob\").outputs[0]\n",
    "\n",
    "        # Tensors we want to evaluate\n",
    "        predictions = graph.get_operation_by_name(\"output/predictions\").outputs[0]\n",
    "\n",
    "        \n",
    "        dataset2_predictions = sess.run(predictions, {input_x: x_dataset2, dropout_keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2_predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset2[:5]\n",
    "#y_dataset2 = np.array(dataset2_label).astype(int)\n",
    "\n",
    "correct_scores_dataset2 = np.array(Y_2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test examples: 10868\n",
      "Accuracy: 0.785793\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = float(sum(dataset2_predictions == correct_scores_dataset2))\n",
    "print(\"Total number of test examples: {}\".format(len(correct_scores_dataset2)))\n",
    "print(\"Accuracy: {:g}\".format(correct_predictions/float(len(correct_scores_dataset2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2_predictions_series = pd.Series(dataset2_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(dataset2_predictions_series.to_frame(), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>left luggage , also luggage storage or bag sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>their name comes from the title of the the fla...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the lyside sulphur can grow from egg to adult ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>istanbul suicide bomber entered turkey as a m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>both describe god as the one divine person , j...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  funny  not_funny  0\n",
       "0  left luggage , also luggage storage or bag sto...      0          1  0\n",
       "1  their name comes from the title of the the fla...      0          1  0\n",
       "2  the lyside sulphur can grow from egg to adult ...      0          1  1\n",
       "3   istanbul suicide bomber entered turkey as a m...      0          1  0\n",
       "4  both describe god as the one divine person , j...      0          1  0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['text', 'funny', 'not_funny', 'predicted_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correct_prediction'] = df.not_funny == df.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>correct_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>left luggage , also luggage storage or bag sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>their name comes from the title of the the fla...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the lyside sulphur can grow from egg to adult ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>istanbul suicide bomber entered turkey as a m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>both describe god as the one divine person , j...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  funny  not_funny  \\\n",
       "0  left luggage , also luggage storage or bag sto...      0          1   \n",
       "1  their name comes from the title of the the fla...      0          1   \n",
       "2  the lyside sulphur can grow from egg to adult ...      0          1   \n",
       "3   istanbul suicide bomber entered turkey as a m...      0          1   \n",
       "4  both describe god as the one divine person , j...      0          1   \n",
       "\n",
       "   predicted_class  correct_prediction  \n",
       "0                0               False  \n",
       "1                0               False  \n",
       "2                1                True  \n",
       "3                0               False  \n",
       "4                0               False  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7857931542142068"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.correct_prediction.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"./evaluating_model_results/dataset2_predictions_base_cnn_100_filters_0.0001LR.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2  with Replacement Predictions (least common word with its most common synonym) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/dataset2_crowdtruth_working_single_word_replacement.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "Y_1 = df['funny']\n",
    "Y_2 = df['not_funny']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame({\"funny\": Y_1.values,\"not_funny\": Y_2.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset2_data_replacement (10868,)\n"
     ]
    }
   ],
   "source": [
    "dataset2_data_replacement, dataset2_label_replacement = X, Y\n",
    "print('dataset2_data_replacement', dataset2_data_replacement.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = processor.transform(dataset2_data_replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10868, 34)\n",
      "(10868, 2)\n"
     ]
    }
   ],
   "source": [
    "x_dataset2_replacement = np.array(list(dataset2))\n",
    "y_dataset2_replacement = np.array(dataset2_label_replacement).astype(int)\n",
    "\n",
    "print(x_dataset2_replacement.shape)\n",
    "print(y_dataset2_replacement.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./runs/cnn/checkpoints/my_training_final_model_2.ckpt\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    session_conf = tf.ConfigProto()\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        # Load the saved meta graph and restore variables\n",
    "        saver = tf.train.import_meta_graph(\"./runs/cnn/checkpoints/my_training_final_model_2.ckpt.meta\")\n",
    "        saver.restore(sess, \"./runs/cnn/checkpoints/my_training_final_model_2.ckpt\")\n",
    "        # Get the placeholders from the graph by name\n",
    "        input_x = graph.get_operation_by_name(\"input_x\").outputs[0]\n",
    "        # input_y = graph.get_operation_by_name(\"input_y\").outputs[0]\n",
    "        dropout_keep_prob = graph.get_operation_by_name(\"dropout_keep_prob\").outputs[0]\n",
    "\n",
    "        # Tensors we want to evaluate\n",
    "        predictions = graph.get_operation_by_name(\"output/predictions\").outputs[0]\n",
    "\n",
    "        \n",
    "        dataset2_predict_replacements = sess.run(predictions, {input_x: x_dataset2_replacement, dropout_keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2_predict_replacements[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_class_replacements = y_dataset2_replacement[:,1]\n",
    "actual_class_replacements[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2_predictions_series = pd.Series(dataset2_predict_replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2_predictions_series[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(dataset2_predictions_series.to_frame(), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>left luggage , also luggage storage or bag sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>their name comes from the title of the the fla...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the lyside sulphur can grow from egg to adult ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>istanbul suicide bomber entered turkey as a m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>both describe god as the one divine person , j...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  funny  not_funny  0\n",
       "0  left luggage , also luggage storage or bag sto...      0          1  0\n",
       "1  their name comes from the title of the the fla...      0          1  0\n",
       "2  the lyside sulphur can grow from egg to adult ...      0          1  1\n",
       "3   istanbul suicide bomber entered turkey as a m...      0          1  0\n",
       "4  both describe god as the one divine person , j...      0          1  0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['text', 'funny', 'not_funny', 'predicted_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correct_prediction'] = df.not_funny == df.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>correct_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>left luggage , also luggage storage or bag sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>their name comes from the title of the the fla...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the lyside sulphur can grow from egg to adult ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>istanbul suicide bomber entered turkey as a m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>both describe god as the one divine person , j...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  funny  not_funny  \\\n",
       "0  left luggage , also luggage storage or bag sto...      0          1   \n",
       "1  their name comes from the title of the the fla...      0          1   \n",
       "2  the lyside sulphur can grow from egg to adult ...      0          1   \n",
       "3   istanbul suicide bomber entered turkey as a m...      0          1   \n",
       "4  both describe god as the one divine person , j...      0          1   \n",
       "\n",
       "   predicted_class  correct_prediction  \n",
       "0                0               False  \n",
       "1                0               False  \n",
       "2                1                True  \n",
       "3                0               False  \n",
       "4                0               False  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7857931542142068"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.correct_prediction.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"./evaluating_model_results/dataset2_one_replacement_predictions_base_cnn_100_filters_0.0001LR.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2 with Replacement Predictions (all possible words with most common synonym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/dataset2_crowdtruth_working_all_replacement.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "Y_1 = df['funny']\n",
    "Y_2 = df['not_funny']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame({\"funny\": Y_1.values,\"not_funny\": Y_2.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset2_data_replacement (10868,)\n"
     ]
    }
   ],
   "source": [
    "dataset2_data_replacement, dataset2_label_replacement = X, Y\n",
    "print('dataset2_data_replacement', dataset2_data_replacement.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = processor.transform(dataset2_data_replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10868, 34)\n",
      "(10868, 2)\n"
     ]
    }
   ],
   "source": [
    "x_dataset2_replacement = np.array(list(dataset2))\n",
    "y_dataset2_replacement = np.array(dataset2_label_replacement).astype(int)\n",
    "\n",
    "print(x_dataset2_replacement.shape)\n",
    "print(y_dataset2_replacement.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./runs/cnn/checkpoints/my_training_final_model_2.ckpt\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    session_conf = tf.ConfigProto()\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        # Load the saved meta graph and restore variables\n",
    "        saver = tf.train.import_meta_graph(\"./runs/cnn/checkpoints/my_training_final_model_2.ckpt.meta\")\n",
    "        saver.restore(sess, \"./runs/cnn/checkpoints/my_training_final_model_2.ckpt\")\n",
    "        # Get the placeholders from the graph by name\n",
    "        input_x = graph.get_operation_by_name(\"input_x\").outputs[0]\n",
    "        # input_y = graph.get_operation_by_name(\"input_y\").outputs[0]\n",
    "        dropout_keep_prob = graph.get_operation_by_name(\"dropout_keep_prob\").outputs[0]\n",
    "\n",
    "        # Tensors we want to evaluate\n",
    "        predictions = graph.get_operation_by_name(\"output/predictions\").outputs[0]\n",
    "\n",
    "        \n",
    "        dataset2_predict_replacements = sess.run(predictions, {input_x: x_dataset2_replacement, dropout_keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2_predict_replacements[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_class_replacements = y_dataset2_replacement[:,1]\n",
    "actual_class_replacements[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2_predictions_series = pd.Series(dataset2_predict_replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2_predictions_series[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(dataset2_predictions_series.to_frame(), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['text', 'funny', 'not_funny', 'predicted_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dont’ belt on death’s door. make the bell and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 see 1 call the like way whether im’ about to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my wife use to be a even customer at mcdonalds...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 can of key have married, after the bride whi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- dont' be irreplaceable, if you bank' be exch...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  funny  not_funny  \\\n",
       "0  dont’ belt on death’s door. make the bell and ...      1          0   \n",
       "1  1 see 1 call the like way whether im’ about to...      1          0   \n",
       "2  my wife use to be a even customer at mcdonalds...      1          0   \n",
       "3  2 can of key have married, after the bride whi...      1          0   \n",
       "4  - dont' be irreplaceable, if you bank' be exch...      1          0   \n",
       "\n",
       "   predicted_class  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correct_prediction'] = df.not_funny == df.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7513801987486198"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.correct_prediction.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>funny</th>\n",
       "      <th>not_funny</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>correct_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dont’ belt on death’s door. make the bell and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 see 1 call the like way whether im’ about to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my wife use to be a even customer at mcdonalds...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 can of key have married, after the bride whi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- dont' be irreplaceable, if you bank' be exch...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  funny  not_funny  \\\n",
       "0  dont’ belt on death’s door. make the bell and ...      1          0   \n",
       "1  1 see 1 call the like way whether im’ about to...      1          0   \n",
       "2  my wife use to be a even customer at mcdonalds...      1          0   \n",
       "3  2 can of key have married, after the bride whi...      1          0   \n",
       "4  - dont' be irreplaceable, if you bank' be exch...      1          0   \n",
       "\n",
       "   predicted_class  correct_prediction  \n",
       "0                0                True  \n",
       "1                0                True  \n",
       "2                0                True  \n",
       "3                0                True  \n",
       "4                0                True  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"./evaluating_model_results/dataset2_preds_all_replacements_base_cnn_100_filters_0.0001LR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
